{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.utils.data import Subset \n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import glob \n",
    "import numpy as np\n",
    "import collada\n",
    "from __future__ import print_function, division\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG #\n",
    "# Adapted from Assignment 2 codebase\n",
    "\n",
    "# TRAINING SETTINGS\n",
    "NUM_EPOCHS = 7\n",
    "\n",
    "# LEARNING RATE SETTINGS\n",
    "BASE_LR = 0.001\n",
    "DECAY_WEIGHT = 0.1 # factor by which the learning rate is reduced.\n",
    "EPOCH_DECAY = 30 # number of epochs after which the learning rate is decayed exponentially by DECAY_WEIGHT.\n",
    "\n",
    "\n",
    "# DATASET INFO\n",
    "NUM_CLASSES = 7 # set the number of classes in your dataset\n",
    "# DATA_DIR = 'CIFAR-10' # to run with the sample dataset, just set to 'hymenoptera_data'\n",
    "\n",
    "# DATALOADER PROPERTIES\n",
    "BATCH_SIZE = 15 # originally 10\n",
    "\n",
    "# GPU SETTINGS\n",
    "#TORCH_DEVICE = 'mps:0' # Enter device ID of your gpu if you want to run on gpu. Otherwise neglect.\n",
    "device = torch.device(\"mps\")\n",
    "GPU_MODE = 1 # set to 1 if want to run on gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to convert the directional metadata to unique IDs so it is easier to process later on\n",
    "# Source: ChatGPT; generated with prompt: 'can you help me make a code that converts that vector into the following ids'\n",
    "\n",
    "def vector_to_direction_id(vector):\n",
    "    # If it's NaN, assign it class 6\n",
    "    if pd.isna(vector):\n",
    "        return 6\n",
    "\n",
    "    # Clean the string (remove brackets, quotes, spaces)\n",
    "    vector = str(vector).strip(\"[]'\").replace(\" \", \"\")\n",
    "\n",
    "    direction_map = {\n",
    "        '1\\\\,0\\\\,0': 0,   # x-up\n",
    "        '-1\\\\,0\\\\,0': 1,  # x-down\n",
    "        '0\\\\,1\\\\,0': 2,   # y-up\n",
    "        '0\\\\,-1\\\\,0': 3,  # y-down\n",
    "        '0\\\\,0\\\\,1': 4,   # z-up\n",
    "        '0\\\\,0\\\\,-1': 5   # z-down\n",
    "    }\n",
    "\n",
    "    # Return the mapped direction or fallback to 6 (treat unknowns as NaN too)\n",
    "    return direction_map.get(vector, 6)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# vector = \"['0\\\\,0\\\\,1']\"\n",
    "# direction_id = vector_to_direction_id(vector)\n",
    "# print(f\"The direction ID for {vector} is: {direction_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata to obtain object labels\n",
    "\n",
    "metadata = pd.read_csv('/Users/ellacho/Documents/NB240/ShapeNetSem-backup/metadata.csv')\n",
    "\n",
    "# Filter to select fullID and up\n",
    "\n",
    "metadata_filtered = metadata[['fullId', 'up']].copy()\n",
    "\n",
    "# Remove wss. prefix from full IDs \n",
    "# Source: https://www.reddit.com/r/learnpython/comments/ozacc3/how_do_i_remove_remove_stuff_like_from_a_string/\n",
    "metadata_filtered['fullId'] = metadata_filtered['fullId'].str.replace('wss.', '')\n",
    "\n",
    "# Change up to have unique IDs \n",
    "up_ID = np.zeros(len(metadata_filtered['up']))\n",
    "for i in range(len(metadata_filtered['up'])):\n",
    "    up_ID[i] = vector_to_direction_id(metadata_filtered['up'][i])\n",
    "\n",
    "metadata_filtered['up'] = up_ID\n",
    "# Create a dictionary\n",
    "metadata_filtered_dict = metadata_filtered.set_index('fullId').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of filenames in binvox png folder\n",
    "# Source: https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = '/Users/ellacho/Documents/NB240/ShapeNetSem-backup/models_binvox_png'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "# Remove suffix to get base name\n",
    "onlyfiles_base = [file.removesuffix('.png') for file in onlyfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#DATA_DIR = '/Users/ellacho/Desktop/test'\n",
    "DATA_DIR = '/Users/ellacho/Documents/NB240/ShapeNetSem-backup/models_binvox_png'\n",
    "\n",
    "class ShapeNetSem(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        self.data_dir = DATA_DIR\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.target_transform = target_transform\n",
    "        self.items = []\n",
    "\n",
    "        for basefilename in onlyfiles_base:\n",
    "            file_paths = glob.glob(f\"{self.data_dir}/**/{basefilename}.png\", recursive=True)\n",
    "            for file_path in file_paths:\n",
    "                if basefilename not in metadata_filtered_dict:\n",
    "                    continue\n",
    "                label = metadata_filtered_dict[basefilename]\n",
    "                self.items.append((file_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.items[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)  # Converts PIL image to a tensor\n",
    "\n",
    "        # Convert label to a tensor\n",
    "        \n",
    "        label = torch.tensor(label, dtype=torch.long).squeeze()  # Ensure labels are long integers (used for classification)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(3,224,1)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('pool1', nn.AvgPool2d(4)),\n",
    "            ('conv2', nn.Conv2d(224,32,1)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('pool2', nn.AvgPool2d(16)),\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('fc', nn.Linear(288,num_classes)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = GPU_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for training and validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and val datasets\n",
    "full_dataset = ShapeNetSem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and val datasets\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define split sizes (80/20)\n",
    "train_size = int(0.8*len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_data, val_data = random_split(full_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset as dict\n",
    "dsets = {}\n",
    "\n",
    "dsets['train'] = train_data\n",
    "dsets['val'] = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset loaders \n",
    "\n",
    "dset_loaders = {}\n",
    "for split in ['train', 'val']:\n",
    "    dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 9829, 'val': 2458}\n"
     ]
    }
   ],
   "source": [
    "# Define dset_sizes\n",
    "\n",
    "dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "print(dset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=100):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model.to(device)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "    losses = {'train': [], 'val': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to eval mode for validation (no need to track gradients)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            counter = 0\n",
    "            # Iterate over data, getting one batch of inputs (images) and labels each time.\n",
    "            for data in dset_loaders[phase]:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Set gradient to zero to delete history of computations in previous epoch\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Print a line every 10 batches so you have something to watch\n",
    "                if counter % 10 == 0:\n",
    "                    print(f\"Reached batch iteration {counter}\")\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Update running loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)  # Multiply by batch size for total loss\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Calculate loss and accuracy for the epoch\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            epoch_acc = running_corrects.float() / dset_sizes[phase]\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            accuracies[phase].append(epoch_acc.item())  # Store accuracy for the phase\n",
    "            losses[phase].append(epoch_loss)  # Store loss for the phase\n",
    "\n",
    "            # Deep copy the model if it's the best so far\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print(f'New best accuracy = {best_acc:.4f}')\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        # lr_scheduler.step()\n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    print('Returning the best model')\n",
    "\n",
    "    return best_model, accuracies, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for modifying learning rate\n",
    "\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/NB240/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/NB240/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if use_gpu:\n",
    "    criterion.to(device)\n",
    "    model_ft.to(device)\n",
    "\n",
    "optimizer_ft = optim.RMSprop(model_ft.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 0/6\n",
      "----------\n",
      "LR is set to 0.001\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.7931 Acc: 0.6960\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.7725 Acc: 0.7071\n",
      "New best accuracy = 0.7071\n",
      "LR is set to 0.001\n",
      "----------\n",
      "Epoch 1/6\n",
      "----------\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.6852 Acc: 0.7133\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.6533 Acc: 0.7380\n",
      "New best accuracy = 0.7380\n",
      "----------\n",
      "Epoch 2/6\n",
      "----------\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.6526 Acc: 0.7272\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.9749 Acc: 0.5285\n",
      "----------\n",
      "Epoch 3/6\n",
      "----------\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.6285 Acc: 0.7403\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.6581 Acc: 0.7217\n",
      "----------\n",
      "Epoch 4/6\n",
      "----------\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.6083 Acc: 0.7488\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.6388 Acc: 0.7465\n",
      "New best accuracy = 0.7465\n",
      "----------\n",
      "Epoch 5/6\n",
      "----------\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.5992 Acc: 0.7503\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.6831 Acc: 0.7400\n",
      "----------\n",
      "Epoch 6/6\n",
      "----------\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "Reached batch iteration 170\n",
      "Reached batch iteration 180\n",
      "Reached batch iteration 190\n",
      "Reached batch iteration 200\n",
      "Reached batch iteration 210\n",
      "Reached batch iteration 220\n",
      "Reached batch iteration 230\n",
      "Reached batch iteration 240\n",
      "Reached batch iteration 250\n",
      "Reached batch iteration 260\n",
      "Reached batch iteration 270\n",
      "Reached batch iteration 280\n",
      "Reached batch iteration 290\n",
      "Reached batch iteration 300\n",
      "Reached batch iteration 310\n",
      "Reached batch iteration 320\n",
      "Reached batch iteration 330\n",
      "Reached batch iteration 340\n",
      "Reached batch iteration 350\n",
      "Reached batch iteration 360\n",
      "Reached batch iteration 370\n",
      "Reached batch iteration 380\n",
      "Reached batch iteration 390\n",
      "Reached batch iteration 400\n",
      "Reached batch iteration 410\n",
      "Reached batch iteration 420\n",
      "Reached batch iteration 430\n",
      "Reached batch iteration 440\n",
      "Reached batch iteration 450\n",
      "Reached batch iteration 460\n",
      "Reached batch iteration 470\n",
      "Reached batch iteration 480\n",
      "Reached batch iteration 490\n",
      "Reached batch iteration 500\n",
      "Reached batch iteration 510\n",
      "Reached batch iteration 520\n",
      "Reached batch iteration 530\n",
      "Reached batch iteration 540\n",
      "Reached batch iteration 550\n",
      "Reached batch iteration 560\n",
      "Reached batch iteration 570\n",
      "Reached batch iteration 580\n",
      "Reached batch iteration 590\n",
      "Reached batch iteration 600\n",
      "Reached batch iteration 610\n",
      "Reached batch iteration 620\n",
      "Reached batch iteration 630\n",
      "Reached batch iteration 640\n",
      "Reached batch iteration 650\n",
      "train Loss: 0.5823 Acc: 0.7617\n",
      "Reached batch iteration 0\n",
      "Reached batch iteration 10\n",
      "Reached batch iteration 20\n",
      "Reached batch iteration 30\n",
      "Reached batch iteration 40\n",
      "Reached batch iteration 50\n",
      "Reached batch iteration 60\n",
      "Reached batch iteration 70\n",
      "Reached batch iteration 80\n",
      "Reached batch iteration 90\n",
      "Reached batch iteration 100\n",
      "Reached batch iteration 110\n",
      "Reached batch iteration 120\n",
      "Reached batch iteration 130\n",
      "Reached batch iteration 140\n",
      "Reached batch iteration 150\n",
      "Reached batch iteration 160\n",
      "val Loss: 0.6068 Acc: 0.7616\n",
      "New best accuracy = 0.7616\n",
      "Training complete in 9m 41s\n",
      "Best val Acc: 0.7616\n",
      "Returning the best model\n",
      "train accuracies by epoch: [0.6960016489028931, 0.7132973670959473, 0.727235734462738, 0.7402583956718445, 0.7488045692443848, 0.7503306269645691, 0.7617254853248596]\n",
      "train losses by epoch: [0.7931044472993385, 0.6852469161442404, 0.6525741942338316, 0.6284949578074208, 0.6083085232672316, 0.5991988985766374, 0.5822779282401447]\n",
      "val accuracies by epoch: [0.7070789337158203, 0.737998366355896, 0.5284784436225891, 0.7217249870300293, 0.7465419173240662, 0.7400325536727905, 0.7615947723388672]\n",
      "val losses by epoch: [0.7725481256612245, 0.6533117513645946, 0.97493578031647, 0.6580828633720163, 0.6388439922021404, 0.6830689665248376, 0.6067905589950289]\n"
     ]
    }
   ],
   "source": [
    "# Run the functions and save the best model in the function model_ft.\n",
    "model_ft, accuracies, losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    print(split, \"accuracies by epoch:\", accuracies[split])\n",
    "    print(split, \"losses by epoch:\", losses[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size = 15, Epochs = 7\n",
    "# Save model\n",
    "torch.save(model_ft.state_dict(), 'shapenetsem_1.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NB240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
